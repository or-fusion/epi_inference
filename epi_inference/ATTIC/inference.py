import csv
import json
import sys
import os
import math
import numpy
import datetime
import random
import pandas as pd
import yaml
import matplotlib.pyplot as plt
from pyutilib.misc import Options
from pyutilib.misc.timing import TicTocTimer
from pyomo.environ import value

from .util import factorial_iterator
from .util import ToStr_JSONEncoder
from . import formulations as frms


#
# Load data from a CSV file generated by 'epiinf collect'
#
def load_csv_data(input_csv):
    df = pd.read_csv(input_csv, parse_dates=['Date'])
    df = df.set_index('Date')

    metadata = {}
    metafile = input_csv[:-4]+"_meta.yml"
    if os.path.isfile(metafile):
        with open(metafile, 'r') as INPUT:
            try:
                metadata = yaml.safe_load(INPUT)
            except yaml.YAMLError as exc:                           # pragma: no cover
                print("ERROR: problem parsing YAML file "+metafile)
                print(exc)
                sys.exit(1)

    return df, metadata

#
# Load geodata from a CSV file
#
"""
TODO - delete

def load_geodata(geodata_csv):
    if not os.path.exists(geodata_csv):                         # pragma: no cover
        print("ERROR: missing file "+geodata_csv)
        sys.exit(1)
    return pd.read_csv(geodata_csv, index_col='geoid')
"""

#
# Process the arguments used for inference
#
def process_config(cfg):
    config = Options()

    config.formulation = cfg['formulation']
    config.ntrials = cfg.get('ntrials', None)
    config.input_csv = cfg['input_csv']
    #config.output_json = cfg.get('output_json',None)
    config.population = cfg.get('population', None)
    config.filter_counties_by_cases = cfg.get('filter_counties_by_cases', 0)
    config.county = cfg.get('county', None)
    config.column = cfg.get('column', None)
    config.reporting_factor = cfg.get('reporting_factor', 1.0)
    config.deltaP = cfg.get('deltaP', 7)
    config.sigma = cfg.get('sigma', None)
    config.gamma = cfg.get('gamma', None)
    config.mobility_json = cfg.get('mobility_json', None)
    config.factor_levels = cfg.get('factor_levels', None)
    config.bootstrap = cfg.get('bootstrap', Options())
    config.analysis_window = cfg.get('analysis_window', Options())

    # TODO - deprecate the use of the geodata CSV file option
    if 'population_csv' not in cfg:
        config.population_csvfile = cfg.get('geodata_csv', config.input_csv[:-4] + "_geodata.csv")
        config.population_csvcolumn = 'pop2010'
        config.population_csvindex = 'geoid'
    else:
        config.population_csvfile = cfg['population_csv']['file']
        config.population_csvcolumn =  cfg['population_csv']['population']
        config.population_csvindex =  cfg['population_csv']['index']

    return config

def check_config(config):
    if config.county is not None and type(config.county) is not str:        # pragma: no cover
        print("ERROR: county id must be specified as a string")
        sys.exit(1)
    try:
        assert(os.path.exists(config.input_csv))
    except:                                                                 # pragma: no cover
        print("ERROR: input file "+config.input_csv+" does not exist")
        raise
    assert type(config.reporting_factor) is float
    
def run_single_node_from_config(df, population_df, CONFIG, verbose):
    column = CONFIG.column
    ntrials = CONFIG.get('ntrials', df.columns)
    formulation = CONFIG.formulation
    filter_counties_by_cases = CONFIG.filter_counties_by_cases
    population_config = CONFIG.population
    population_csvcolumn = CONFIG.population_csvcolumn
    sigma = CONFIG.sigma
    gamma = CONFIG.gamma
    report_delay = CONFIG.deltaP
    reporting_factor = CONFIG.reporting_factor
    analysis_window = CONFIG.analysis_window

    all_results = list()
    ndx = 0

    for t in df:
        if column is not None and t != column:
            continue
        ndx = ndx+1
        if not ntrials is None and ndx > ntrials:
            break

        if population_config is None:
            if t not in population_df[population_csvcolumn]:                # pragma: no cover
                print("WARNING: county "+str(t)+" does not have population data available.")
                continue
            population = population_df[population_csvcolumn][t]
        else:
            population = population_config
        cm_rep_cases = df[t].to_list()
        Cdates = df.index.to_list()

        #if df[t][-1] == 0:
        #    results = {'est_beta':None, 'status':'skipped', 'msg':'No case data', 'population': population, 'total_cases': float(df[t][-1])}

        if df[t][-1] <= filter_counties_by_cases:
            results = {'est_beta':None, 'status':'skipped', 'msg':'cumulative cases <= {} (filter_counties_by_cases)'.format(filter_counties_by_cases), 'population': population, 'total_cases': float(df[t][-1])}

        elif formulation == 'decay-lsq':
            results = frms.run_decay_lsq(cm_rep_cases=cm_rep_cases,
                                                      population=population,
                                                      sigma=sigma,
                                                      gamma=gamma,
                                                      report_delay=report_delay,
                                                      reporting_factor=reporting_factor,
                                                      analysis_window=analysis_window,
                                                      Cdates=Cdates)
        elif formulation == 'decay-blike':
            results = frms.run_decay_blike(cm_rep_cases=cm_rep_cases,
                                           population=population,
                                           sigma=sigma,
                                           gamma=gamma,
                                           report_delay=report_delay,
                                           reporting_factor=reporting_factor,
                                           analysis_window=analysis_window,
                                           Cdates=Cdates)
            """
            elif formulation == 'decay-multibeta-lsq':
                results = frms.run_decay_multibeta_lsq(cm_rep_cases=cm_rep_cases,
                                         population=population,
                                         sigma=sigma,
                                         gamma=gamma,
                                         deltaP=report_delay,
                                         reporting_factor=reporting_factor)
            #                                         analysis_window=analysis_window)
            """
        else:                                                               # pragma: no cover
            print("ERROR: unknown formulation '%s'" % formulation)
            sys.exit(1)

        results['FIPS'] = t
        #
        # Collect results in a list
        #
        all_results.append( results )
    return all_results

def run_multinode_from_config(df, population_df, CONFIG, verbose):
    formulation = CONFIG.formulation
    sigma = CONFIG.sigma
    gamma = CONFIG.gamma
    filter_counties_by_cases = CONFIG.filter_counties_by_cases
    report_delay = CONFIG.deltaP
    reporting_factor = CONFIG.reporting_factor
    analysis_window = CONFIG.analysis_window
    mobility_dict = CONFIG.mobility_dict
    bootstrap = CONFIG.bootstrap
    bootstrap_percentile = bootstrap.get('percentile',5)
    bootstrap_n = bootstrap.get('n',100)
    bootstrap_seed = bootstrap.get('seed',None)
    bootstrap_value = bootstrap.get('value','est_beta')
    bootstrap_output_csv = bootstrap.get('output_csv', None)
    bootstrap_weighted = bootstrap.get('weighted', False)

    #
    # Error checking
    #
    nodes = [val for val in df.keys().to_list()]
    flag=False
    active_nodes = []
    for n in nodes:
        if not n in population_df:                                      # pragma: no cover
            flag=True
            print("Population is missing for county: "+str(n))
        if df[n][-1] > filter_counties_by_cases:
            active_nodes.append(n)
        else:
            print("WARNING: Skipping county '"+str(n)+"' in multinode estimation because it has no cases")
    if flag:                                                            # pragma: no cover
        sys.exit(1)
    if len(active_nodes) == 0:
        return {'fraction_of_counties_with_cases': 0, 'est_beta':None}

    if bootstrap:
        if bootstrap_weighted:
            bootstrap_weights = population_df[active_nodes].copy()
        else:
            bootstrap_weights = population_df[active_nodes].copy()
            bootstrap_weights[bootstrap_weights.index] = 1

        #testing_bootstrap = population_df[active_nodes].copy()
        #testing_bootstrap[testing_bootstrap.index] = 0

        if bootstrap_seed is not None:
            random.seed(bootstrap_seed)

        all_results = []
        for i in range(bootstrap_n):
            DF = df.sample(n=len(df.keys()), replace=True, axis=1, random_state=random.randint(1000000,9999999), weights=bootstrap_weights)
            sampled_nodes = [val for val in DF.keys().to_list()]

            #for n in sampled_nodes:
            #    testing_bootstrap[n] = testing_bootstrap[n] + 1
            populations = population_df[sampled_nodes]

            if formulation == 'multinode-decay-lsq':
                results = frms.run_multinode_decay_lsq(DF,
                                                       populations=populations,
                                                       sigma=sigma,
                                                       gamma=gamma,
                                                       report_delay=report_delay,
                                                       analysis_window=dict(),
                                                       reporting_factor=reporting_factor,
                                                       Cdates=df.index.tolist())
            elif formulation == 'multinode-decay-blike':
                results = frms.run_multinode_decay_blike(DF,
                                         population=populations,
                                         sigma=sigma,
                                         gamma=gamma,
                                         report_delay=report_delay,
                                         analysis_window=dict(),
                                         reporting_factor=reporting_factor,
                                         Cdates=df.index.tolist())
#            elif formulation == 'multinode-decay-multibeta-lsq':
#                results = frms.run_multinode_decay_multibeta_lsq(DF,
#                                               population=populations,
#                                               sigma=sigma,
#                                               gamma=gamma,
#                                               deltaP=report_delay,
#                                               reporting_factor=reporting_factor)
            else:
                raise RuntimeError("Unknown formulation: "+formulation)
            all_results.append(results)

        #print(testing_bootstrap/ (len(testing_bootstrap)*bootstrap_n))
        #print(bootstrap_weights/ sum(bootstrap_weights))
    #
    # Do the estimate with all the data
    #

    if formulation == 'multinode-decay-lsq':
        results = frms.run_multinode_decay_lsq(df[active_nodes],
                                         populations=population_df[active_nodes],
                                         sigma=sigma,
                                         gamma=gamma,
                                         report_delay=report_delay,
                                         reporting_factor=reporting_factor,
                                         analysis_window=dict(),
                                         Cdates=df.index.tolist())
    elif formulation == 'multinode-decay-blike':
        results = frms.run_multinode_decay_blike(df[active_nodes],
                                         population=population_df[active_nodes],
                                         sigma=sigma,
                                         gamma=gamma,
                                         deltaP=report_delay,
                                         reporting_factor=reporting_factor,
                                         analysis_window=dict(),
                                         Cdates=df.index.tolist())
    elif formulation == 'multinode-mobility-decay-lsq':
        results = frms.run_multinode_mobility_decay_lsq(df[active_nodes],
                                                        populations=population_df[active_nodes],
                                                        mobility=mobility_dict,
                                                        sigma=sigma,
                                                        gamma=gamma,
                                                        report_delay=report_delay,
                                                        reporting_factor=reporting_factor,
                                                        analysis_window=analysis_window,
                                                        Cdates=df.index.tolist())
    elif formulation == 'multinode-mobility-window-decay-lsq':
        results = frms.run_multinode_mobility_window_decay_lsq(df[active_nodes],
                                                        populations=population_df[active_nodes],
                                                        mobility=mobility_dict,
                                                        sigma=sigma,
                                                        gamma=gamma,
                                                        report_delay=report_delay,
                                                        reporting_factor=reporting_factor,
                                                        analysis_window=analysis_window,
                                                        Cdates=df.index.tolist())
    elif formulation == 'multinode-mobility-time-varying-decay-lsq':
        results = frms.run_multinode_mobility_time_varying_decay_lsq(df[active_nodes],
                                                        populations=population_df[active_nodes],
                                                        mobility=mobility_dict,
                                                        sigma=sigma,
                                                        gamma=gamma,
                                                        report_delay=report_delay,
                                                        reporting_factor=reporting_factor,
                                                        analysis_window=analysis_window,
                                                        Cdates=df.index.tolist())
#    elif formulation == 'multinode-decay-multibeta-lsq':
#        results = frms.run_multinode_decay_multibeta_lsq(df[active_nodes],
#                                           population=population_df[active_nodes],
#                                           sigma=sigma,
#                                           gamma=gamma,
#                                           deltaP=report_delay,
#                                           reporting_factor=reporting_factor)
    else:
        raise RuntimeError("Unknown formulation: "+formulation)


    #
    # Compute the confidence interval
    #
    if bootstrap:
        values = [r[bootstrap_value] for r in all_results]
        values.sort()
        results['bootstrap_mean_beta'] = numpy.mean(values)
        #results['bootstrap_mean_beta'] = statistics.mean(values)
        quantiles = [ 
            numpy.quantile(values, bootstrap_percentile/100, axis=0),
            numpy.quantile(values, 1.0-bootstrap_percentile/100, axis=0)
            ]
        #quantiles = statistics.quantiles(values, n=100//bootstrap_percentile)
        results['bootstrap_'+str(bootstrap_percentile)+'%'] = quantiles[0]
        results['bootstrap_'+str(100-bootstrap_percentile)+'%'] = quantiles[-1]
        if verbose:
            print("Bootstrap Value")
            print(values)
            print("Quantiles")
            print(quantiles)
        if bootstrap_output_csv is not None:
            bootstrap_df = pd.DataFrame(values, columns=["est_beta"])
            bootstrap_df.to_csv(bootstrap_output_csv, quoting=csv.QUOTE_NONNUMERIC)

    assert(len(nodes) == len(df.keys()))
    results['num_counties'] = len(df.keys())
    results['fraction_of_counties_with_cases'] = len(active_nodes)/len(df.keys())
    return [results]

def run_multibeta_from_config(df, population_df, CONFIG, verbose):
    formulation = CONFIG.formulation
    sigma = CONFIG.sigma
    gamma = CONFIG.gamma
    filter_counties_by_cases = CONFIG.filter_counties_by_cases
    
    report_delay = CONFIG.deltaP
    reporting_factor = CONFIG.reporting_factor
    analysis_window = CONFIG.analysis_window

    #
    # Error checking
    #
    nodes = [val for val in df.keys().to_list()]
    flag=False
    active_nodes = []
    for n in nodes:
        if not n in population_df:                                      # pragma: no cover
            flag=True
            print("Population is missing for county: "+str(n))
        if df[n][-1] > filter_counties_by_cases:
            active_nodes.append(n)
        else:
            print("WARNING: Skipping county '"+str(n)+"' in multinode estimation because it has no cases")
    if flag:                                                            # pragma: no cover
        sys.exit(1)
    if len(active_nodes) == 0:
        return {'fraction_of_counties_with_cases': 0, 'est_beta':{}, 'est_omega':{}}

    #
    # Do the estimate with all the data
    #
    if formulation == 'multibeta-singleomega-decay-lsq':
        results = frms.run_multibeta_singleomega_decay_lsq(df[active_nodes],
                                         populations=population_df[active_nodes],
                                         sigma=sigma,
                                         gamma=gamma,
                                         report_delay=report_delay,
                                         reporting_factor=reporting_factor,
                                         analysis_window=dict())
    elif formulation == 'multibeta-singleomegawin-decay-lsq':
        results = frms.run_multibeta_singleomegawin_decay_lsq(df[active_nodes],
                                         populations=population_df[active_nodes],
                                         sigma=sigma,
                                         gamma=gamma,
                                         report_delay=report_delay,
                                         reporting_factor=reporting_factor,
                                         analysis_window=analysis_window)
    elif formulation == 'multibeta-singleomegawin-decay-l1':
        results = frms.run_multibeta_singleomegawin_decay_l1(df[active_nodes],
                                         populations=population_df[active_nodes],
                                         sigma=sigma,
                                         gamma=gamma,
                                         report_delay=report_delay,
                                         reporting_factor=reporting_factor,
                                         analysis_window=analysis_window)
    elif formulation == 'multibeta-multiwin-decay-lsq':
        results = frms.run_multibeta_multiwin_decay_lsq(df[active_nodes],
                                         populations=population_df[active_nodes],
                                         sigma=sigma,
                                         gamma=gamma,
                                         report_delay=report_delay,
                                         reporting_factor=reporting_factor,
                                         analysis_window=analysis_window,
                                         Cdates=df.index.tolist())
    else:
        raise RuntimeError("ERROR: Unknown model - "+formulation)

    assert(len(nodes) == len(df.keys()))
    results['num_counties'] = len(df.keys())
    results['fraction_of_counties_with_cases'] = len(active_nodes)/len(df.keys())
    return [results]


"""
Example YAML file
inference:
   - formulation: delay-ln-lsq
     deltaE: 5
     deltaI: 4
     deltaP: 7 # reporting delay (from time of infection to reported case)
     reportingfac: 1.0 # reporting factor (5 means actual cases = 5*reported)
     population: 4500000
     datafilename: data.csv
     daysbefore: 5  # number of days to include before the first case
     daysafter: 28  # number of days of data to include after the first case
   - formulation: delay-lsq
     sigma: 0.1923076923 # 1/5.2
     gamma: 0.25 # 1/4
     deltaP: 7
     population: 4500000
     datafilename: data.csv
     daysbefore: 5  # number of days to include before the first case
     daysafter: 28  # number of days of data to include after the first case
"""
def run(args):
    with open(args.config_file, 'r') as fd:
        config = yaml.safe_load(fd)

    if 'inference' not in config:
        raise ValueError('No "inference" key found in the YAML config')

    timer = TicTocTimer()
    for cfg in config.get('inference', []):
        timer.tic('Starting Inference')
        verbose = cfg.get('verbose', args.verbose)
        factors = cfg.get('factors', None)
        output_csv = cfg.get('output_csv', None)
        output_json = cfg.get('output_json', None)

        assert output_csv is not None or output_json is not None 
        assert type(verbose) is bool
        
        config = process_config(cfg)
        if verbose:
            print('Inference Configuration:\n', config)

        all_results = []

        if factors is None:
            config_list = [config]
        else:
            config_list = factorial_iterator(factors, config)

        for CONFIG in config_list:
            try:
                population_df = pd.read_csv(CONFIG.population_csvfile, encoding="ISO-8859-1", dtype={CONFIG.population_csvindex:'str'})
                population_df = population_df.set_index(CONFIG.population_csvindex)
            except:
                print("ERROR reading file "+CONFIG.population_csvfile)
                raise
            check_config(CONFIG)
            if CONFIG.population is None and CONFIG.county is not None:
                CONFIG.population = population_df[CONFIG.population_csvcolumn][CONFIG.county]
                if verbose:
                    print("County: %s    Population: %s" % (str(CONFIG.county), str(CONFIG.population)))

            print("Input File: "+CONFIG.input_csv+' with column '+str(CONFIG.column))
            #
            # Load the dataframe and experimental metadata (if it's available)
            #
            df, metadata = load_csv_data(CONFIG.input_csv)
            data = metadata.get('simulation parameters', None)
            if data is not None:
                if CONFIG.verbose:
                    print('parameters used to create data')
                    print(data)
                for key, value in data.items():
                    CONFIG[key] = value

            #
            # load mobility data if needed
            #
            CONFIG.mobility_dict = {}
            if CONFIG.mobility_json is not None:
                try:
                    with open(CONFIG.mobility_json, 'r') as fd:
                        CONFIG.mobility_dict = json.load(fd)
                except:
                    print("ERROR reading file " + CONFIG.mobility_json)
                    raise
            
            #
            # Execute inference
            #
            if CONFIG.formulation in ['decay-lsq', 'decay-blike', 'decay-multibeta-lsq']:
                results = run_single_node_from_config(df, population_df, CONFIG, verbose)
            elif CONFIG.formulation in ['multinode-mobility-time-varying-decay-lsq', 'multinode-mobility-window-decay-lsq', 'multinode-mobility-decay-lsq', 'multinode-decay-lsq', 'multinode-decay-blike', 'multinode-decay-multibeta-lsq']:
                results = run_multinode_from_config(df, population_df[CONFIG.population_csvcolumn], CONFIG, verbose)
            elif CONFIG.formulation.startswith('multibeta-'):
                results = run_multibeta_from_config(df, population_df[CONFIG.population_csvcolumn], CONFIG, verbose)
            else:
                raise ValueError('Invalid formulation', CONFIG.formulation, 'found in YAML file inference section.')
            #
            # Augment reported results
            #
            for trial in results:
                if data is not None:
                    trial['est_R0'] = trial['est_beta']/float(data['gamma'])
                    for key, value in data.items():
                        if not key in trial:
                            trial[key] = value
                if CONFIG.factor_levels is not None:
                    for key, value in CONFIG.factor_levels.items():
                        if not key in trial:
                            trial[key] = value
                all_results.append( trial )
                
        #
        # Save results
        #
        if output_csv:
            print("Writing results in file "+output_csv)
            filedir = os.path.dirname(output_csv)
            if not os.path.exists(filedir):
                os.makedirs(filedir)
            all_df = pd.DataFrame(all_results)
            all_df.to_csv(output_csv, index=False, quoting=csv.QUOTE_NONNUMERIC)
        else:
            print("Writing results in file "+output_json)
            filedir = os.path.dirname(output_json)
            if not os.path.exists(filedir):
                os.makedirs(filedir)
            with open(output_json, 'w') as OUTPUT:
                tmp = json.dumps(all_results, indent=4, cls=ToStr_JSONEncoder)
                OUTPUT.write(tmp)
            all_df = None
        #
        # Create a YAML file with metadata
        #
        metadata = {}
        metadata['timestamp'] = str(datetime.datetime.now())
        metadata['configuration'] = {}
        for key in cfg:
            metadata['configuration'][key] = cfg[key]
        if output_csv:
            metaoutput = output_csv[:-4]+"_meta.yml" 
        elif output_json.endswith('.json'):
            metaoutput = output_json[:-5]+"_meta.yml" 
        elif output_json.endswith('.jsn'):
            metaoutput = output_json[:-4]+"_meta.yml" 
        print("Writing results metadata in file "+metaoutput)
        with open(metaoutput, 'w') as OUTPUT:
            yaml.dump(metadata, OUTPUT)
        #
        # Print data
        #
        if verbose:
            if all_df is None:
                print(json.dumps(all_results, indent=4, cls=ToStr_JSONEncoder))
            else:
                pd.set_option('display.max_rows', 100000)
                print(all_df)

        timer.toc('Completed Inference')

    timer.tic('Completed All Inference Computations')


"""
This is the previous version of 'run'.  I'm caching this here so we can
quickly go back to it.

Example YAML file
inference:
   - formulation: delay-ln-lsq
     deltaE: 5
     deltaI: 4
     deltaP: 7 # reporting delay (from time of infection to reported case)
     reportingfac: 1.0 # reporting factor (5 means actual cases = 5*reported)
     population: 4500000
     datafilename: data.csv
     daysbefore: 5  # number of days to include before the first case
     daysafter: 28  # number of days of data to include after the first case
   - formulation: delay-lsq
     sigma: 0.1923076923 # 1/5.2
     gamma: 0.25 # 1/4
     deltaP: 7
     population: 4500000
     datafilename: data.csv
     daysbefore: 5  # number of days to include before the first case
     daysafter: 28  # number of days of data to include after the first case

def run_old(args):
    with open(args.config_file, 'r') as fd:
        config = yaml.safe_load(fd)

    if 'inference' and 'batch_inference' not in config:
        raise ValueError('No inference or batch_inference key found in the YAML config')

    for cfg in config.get('inference', []):
        all_results = list()
        verbose = cfg.get('verbose', args.verbose)
        assert type(verbose) is bool
        
        if verbose:
            print('Inference Configuration:', cfg)
        
        formulation = cfg['formulation']
        ntrials = cfg.get('ntrials', None)

        input_csv = cfg['input_csv']
        assert(os.path.exists(input_csv))
        geodata_csv = input_csv[:-4] + "_geodata.csv"
        geodata_df = load_geodata(geodata_csv)

        population = cfg.get('population', None)
        county = cfg.get('county', None)
        assert(not ((population is None) and (county is None)))

        column = cfg.get('column', None)
        reporting_factor = cfg.get('reporting_factor', 1.0)
        assert type(reporting_factor) is float

        print("Input File: "+input_csv+' with column '+str(column))
        if formulation == 'decay-lsq' or formulation == 'decay-blike':
            df, metadata = load_csv_data(input_csv)
            data = metadata['simulation parameters']
            ntrials = cfg.get('ntrials', df.columns)
            if verbose:
                print('parameters used to create data')
                print(data)

            if population is None:
                population = geodata_df['pop2010'][county]
                if verbose:
                    print("County: %s    Population: %s" % (str(county), str(population)))

            ndx = 0
            for t in df:
                if column is not None and t != column:
                    continue
                
                ndx = ndx+1
                if not ntrials is None and ndx > ntrials:
                    break

                # get the data - this will change with Bill's new stuff
                cm_rep_cases = df[t].to_list()

                sigma = cfg['sigma']
                gamma = cfg['gamma']
                deltaP = cfg['deltaP']

                if formulation == 'decay-lsq':
                    results = frms.run_decay_lsq(cm_rep_cases=cm_rep_cases,
                                                 population=population,
                                                 sigma=sigma,
                                                 gamma=gamma,
                                                 deltaP=deltaP,
                                                 reporting_factor=reporting_factor)
                else:
                    # formulation == 'decay-blike'
                    results = frms.run_decay_blike(cm_rep_cases=cm_rep_cases,
                                                   population=population,
                                                   sigma=sigma,
                                                   gamma=gamma,
                                                   deltaP=deltaP,
                                                   reporting_factor=reporting_factor)

                results['est_R0'] = results['est_beta']/float(data['gamma'])
                results['true_beta'] = float(data['beta'])
                results['true_R0'] = float(data['beta'])/float(data['gamma'])
                all_results.append(results)

        elif formulation == 'delay-ln-lsq':
            raise NotImplementedError('Formulation ' + formulation + ' is not ready.')
            df, metadata = load_csv_data(input_csv)
            data = metadata['simulation parameters']
            if population is None:
                population = geodata_df['pop2010'][county]
                if verbose:
                    print("County: %s    Population: %s" % (str(county), str(population)))
            if verbose:
                print('parameters used to create data')
                print(data)
            for col in df:
                # get the data - this will change with Bill's new stuff
                cm_rep_cases = df[col].to_list()

                deltaE = cfg['deltaE']
                assert type(deltaE) is int and deltaE > 0
                deltaI = cfg['deltaI']
                assert type(deltaI) is int and deltaI > 0
                deltaP = cfg['deltaP']
                assert type(deltaP) is int and deltaP > 0

                results = frms.run_delay_ln_lsq(cm_rep_cases=cm_rep_cases,
                                                population=population,
                                                deltaE=deltaE,
                                                deltaI=deltaI,
                                                deltaP=deltaP,
                                                reporting_factor=reporting_factor,
                                                geodata_df=geodata_df)

                results['est_R0'] = results['est_beta']/float(data['gamma'])
                results['true_beta'] = float(data['beta'])
                results['true_R0'] = float(data['beta'])/float(data['gamma'])
                print(results)

        elif formulation == 'delay-lsq':
            #all_results = list()
            df, metadata = load_csv_data(input_csv)
            data = metadata['simulation parameters']
            if population is None:
                population = geodata_df['pop2010'][county]
                if verbose:
                    print("County: %s    Population: %s" % (str(county), str(population)))
            if verbose:
                print('parameters used to create data')
                print(data)
            for col in df:
                # get the data - this will change with Bill's new stuff
                cm_rep_cases = df[col].to_list()

                deltaE = cfg['deltaE']
                assert type(deltaE) is int and deltaE > 0
                deltaI = cfg['deltaI']
                assert type(deltaI) is int and deltaI > 0
                deltaP = cfg['deltaP']
                assert type(deltaP) is int and deltaP > 0

                results = frms.run_delay_lsq(cm_rep_cases=cm_rep_cases,
                                             population=population,
                                             deltaE=deltaE,
                                             deltaI=deltaI,
                                             deltaP=deltaP,
                                             reporting_factor=reporting_factor,
                                             geodata_df=geodata_df)

                results['est_R0'] = results['est_beta']/float(data['gamma'])
                results['true_beta'] = float(data['beta'])
                results['true_R0'] = float(data['beta'])/float(data['gamma'])

        else:
            raise ValueError('Invalid formulation', formulation, 'found in YAML file inference section.')

        all_df = pd.DataFrame(all_results)
        all_df.to_csv('inference_tests.csv', index=False, quoting=csv.QUOTE_NONNUMERIC)
        pd.set_option('display.max_rows', 100000)
        print(all_df)

    #
    # Process batch_inference blocks
    #
    for cfg in config.get('batch_inference', []):
        verbose = cfg.get('verbose', args.verbose)
        factors = cfg.get('factors', None)
        config = cfg.get('config', None)
        output = cfg.get('output', None)

        assert factors is not None
        assert config is not None
        assert output is not None
        assert type(verbose) is bool
        
        config = process_config(config)
        if verbose:
            print('Inference Configuration:\n', config)
        all_results = list()

        for CONFIG in factorial_iterator(factors, config):
            geodata_df = load_geodata(CONFIG.geodata_csv)
            if CONFIG.population is None:
                CONFIG.population = geodata_df['pop2010'][CONFIG.county]
                if verbose:
                    print("County: %s    Population: %s" % (str(CONFIG.county), str(CONFIG.population)))

            check_config(CONFIG)
            print("Input File: "+CONFIG.input_csv+' with column '+str(CONFIG.column))

            if CONFIG.formulation == 'decay-lsq' or CONFIG.formulation == 'decay-blike':
                all_results.extend( run_decay_lsq(CONFIG, verbose) )
            else:
                raise ValueError('Invalid formulation', CONFIG.formulation, 'found in YAML file inference section.')

        all_df = pd.DataFrame(all_results)
        #
        # Save results
        #
        print("Writing results in file "+output)
        all_df.to_csv(output, index=False, quoting=csv.QUOTE_NONNUMERIC)
        #
        # Create a YAML file with metadata
        #
        metadata = {}
        metadata['timestamp'] = str(datetime.datetime.now())
        metadata['configuration'] = {}
        for key in cfg:
            metadata['configuration'][key] = cfg[key]
        metaoutput = output[:-4]+"_meta.yml" 
        print("Writing results metadata in file "+metaoutput)
        with open(metaoutput, 'w') as OUTPUT:
            yaml.dump(metadata, OUTPUT)
        #
        # Print data
        #
        pd.set_option('display.max_rows', 100000)
        print(all_df)
"""

"""
    df = pd.DataFrame(results)
    if args.resfile is not None:
        df.to_csv(args.resfile, index=False)

    print(df)
    print('Mean values:')
    print(df.mean())
    print(df.std())
    df.hist()
    #plt.title('foo')
    #plt.show()
"""
